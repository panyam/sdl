/* tslint:disable */
/* eslint-disable */
/**
 * leetcoach/v1/models.proto
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: version not set
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import * as runtime from '../runtime';
import type {
  LlmServiceGenerateTextContentRequest,
  LlmServiceReviewTextContentRequest,
  LlmServiceSuggestSectionsRequest,
  RpcStatus,
  V1GenerateDefaultPromptsResponse,
  V1GenerateTextContentResponse,
  V1ReviewTextContentResponse,
  V1SimpleLlmQueryRequest,
  V1SimpleLlmQueryResponse,
  V1SuggestSectionsResponse,
} from '../models/index';
import {
    LlmServiceGenerateTextContentRequestFromJSON,
    LlmServiceGenerateTextContentRequestToJSON,
    LlmServiceReviewTextContentRequestFromJSON,
    LlmServiceReviewTextContentRequestToJSON,
    LlmServiceSuggestSectionsRequestFromJSON,
    LlmServiceSuggestSectionsRequestToJSON,
    RpcStatusFromJSON,
    RpcStatusToJSON,
    V1GenerateDefaultPromptsResponseFromJSON,
    V1GenerateDefaultPromptsResponseToJSON,
    V1GenerateTextContentResponseFromJSON,
    V1GenerateTextContentResponseToJSON,
    V1ReviewTextContentResponseFromJSON,
    V1ReviewTextContentResponseToJSON,
    V1SimpleLlmQueryRequestFromJSON,
    V1SimpleLlmQueryRequestToJSON,
    V1SimpleLlmQueryResponseFromJSON,
    V1SimpleLlmQueryResponseToJSON,
    V1SuggestSectionsResponseFromJSON,
    V1SuggestSectionsResponseToJSON,
} from '../models/index';

export interface LlmServiceGenerateDefaultPromptsRequest {
    designId: string;
    sectionId: string;
    body: object;
}

export interface LlmServiceGenerateTextContentOperationRequest {
    designId: string;
    sectionId: string;
    body: LlmServiceGenerateTextContentRequest;
}

export interface LlmServiceReviewTextContentOperationRequest {
    designId: string;
    sectionId: string;
    body: LlmServiceReviewTextContentRequest;
}

export interface LlmServiceSimpleLlmQueryRequest {
    body: V1SimpleLlmQueryRequest;
}

export interface LlmServiceSuggestSectionsOperationRequest {
    designId: string;
    body: LlmServiceSuggestSectionsRequest;
}

/**
 * 
 */
export class LlmServiceApi extends runtime.BaseAPI {

    /**
     * GenerateDefaultPrompts generates and saves default prompts for a section.
     */
    async llmServiceGenerateDefaultPromptsRaw(requestParameters: LlmServiceGenerateDefaultPromptsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<V1GenerateDefaultPromptsResponse>> {
        if (requestParameters['designId'] == null) {
            throw new runtime.RequiredError(
                'designId',
                'Required parameter "designId" was null or undefined when calling llmServiceGenerateDefaultPrompts().'
            );
        }

        if (requestParameters['sectionId'] == null) {
            throw new runtime.RequiredError(
                'sectionId',
                'Required parameter "sectionId" was null or undefined when calling llmServiceGenerateDefaultPrompts().'
            );
        }

        if (requestParameters['body'] == null) {
            throw new runtime.RequiredError(
                'body',
                'Required parameter "body" was null or undefined when calling llmServiceGenerateDefaultPrompts().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/v1/designs/{designId}/sections/{sectionId}/prompts:generateDefaults`.replace(`{${"designId"}}`, encodeURIComponent(String(requestParameters['designId']))).replace(`{${"sectionId"}}`, encodeURIComponent(String(requestParameters['sectionId']))),
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters['body'] as any,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => V1GenerateDefaultPromptsResponseFromJSON(jsonValue));
    }

    /**
     * GenerateDefaultPrompts generates and saves default prompts for a section.
     */
    async llmServiceGenerateDefaultPrompts(requestParameters: LlmServiceGenerateDefaultPromptsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<V1GenerateDefaultPromptsResponse> {
        const response = await this.llmServiceGenerateDefaultPromptsRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * GenerateTextContent attempts to generate content for a text section.
     */
    async llmServiceGenerateTextContentRaw(requestParameters: LlmServiceGenerateTextContentOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<V1GenerateTextContentResponse>> {
        if (requestParameters['designId'] == null) {
            throw new runtime.RequiredError(
                'designId',
                'Required parameter "designId" was null or undefined when calling llmServiceGenerateTextContent().'
            );
        }

        if (requestParameters['sectionId'] == null) {
            throw new runtime.RequiredError(
                'sectionId',
                'Required parameter "sectionId" was null or undefined when calling llmServiceGenerateTextContent().'
            );
        }

        if (requestParameters['body'] == null) {
            throw new runtime.RequiredError(
                'body',
                'Required parameter "body" was null or undefined when calling llmServiceGenerateTextContent().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/v1/designs/{designId}/sections/{sectionId}/text:generate`.replace(`{${"designId"}}`, encodeURIComponent(String(requestParameters['designId']))).replace(`{${"sectionId"}}`, encodeURIComponent(String(requestParameters['sectionId']))),
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: LlmServiceGenerateTextContentRequestToJSON(requestParameters['body']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => V1GenerateTextContentResponseFromJSON(jsonValue));
    }

    /**
     * GenerateTextContent attempts to generate content for a text section.
     */
    async llmServiceGenerateTextContent(requestParameters: LlmServiceGenerateTextContentOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<V1GenerateTextContentResponse> {
        const response = await this.llmServiceGenerateTextContentRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * ReviewTextContent asks the LLM to review existing text content.
     */
    async llmServiceReviewTextContentRaw(requestParameters: LlmServiceReviewTextContentOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<V1ReviewTextContentResponse>> {
        if (requestParameters['designId'] == null) {
            throw new runtime.RequiredError(
                'designId',
                'Required parameter "designId" was null or undefined when calling llmServiceReviewTextContent().'
            );
        }

        if (requestParameters['sectionId'] == null) {
            throw new runtime.RequiredError(
                'sectionId',
                'Required parameter "sectionId" was null or undefined when calling llmServiceReviewTextContent().'
            );
        }

        if (requestParameters['body'] == null) {
            throw new runtime.RequiredError(
                'body',
                'Required parameter "body" was null or undefined when calling llmServiceReviewTextContent().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/v1/designs/{designId}/sections/{sectionId}/text:review`.replace(`{${"designId"}}`, encodeURIComponent(String(requestParameters['designId']))).replace(`{${"sectionId"}}`, encodeURIComponent(String(requestParameters['sectionId']))),
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: LlmServiceReviewTextContentRequestToJSON(requestParameters['body']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => V1ReviewTextContentResponseFromJSON(jsonValue));
    }

    /**
     * ReviewTextContent asks the LLM to review existing text content.
     */
    async llmServiceReviewTextContent(requestParameters: LlmServiceReviewTextContentOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<V1ReviewTextContentResponse> {
        const response = await this.llmServiceReviewTextContentRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * SimpleLlmQuery sends a basic prompt to the LLM. Primarily for initial testing and simple use cases.
     */
    async llmServiceSimpleLlmQueryRaw(requestParameters: LlmServiceSimpleLlmQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<V1SimpleLlmQueryResponse>> {
        if (requestParameters['body'] == null) {
            throw new runtime.RequiredError(
                'body',
                'Required parameter "body" was null or undefined when calling llmServiceSimpleLlmQuery().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/v1/llm/query`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: V1SimpleLlmQueryRequestToJSON(requestParameters['body']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => V1SimpleLlmQueryResponseFromJSON(jsonValue));
    }

    /**
     * SimpleLlmQuery sends a basic prompt to the LLM. Primarily for initial testing and simple use cases.
     */
    async llmServiceSimpleLlmQuery(requestParameters: LlmServiceSimpleLlmQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<V1SimpleLlmQueryResponse> {
        const response = await this.llmServiceSimpleLlmQueryRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * SuggestSections recommends relevant sections to add based on existing ones.
     */
    async llmServiceSuggestSectionsRaw(requestParameters: LlmServiceSuggestSectionsOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<V1SuggestSectionsResponse>> {
        if (requestParameters['designId'] == null) {
            throw new runtime.RequiredError(
                'designId',
                'Required parameter "designId" was null or undefined when calling llmServiceSuggestSections().'
            );
        }

        if (requestParameters['body'] == null) {
            throw new runtime.RequiredError(
                'body',
                'Required parameter "body" was null or undefined when calling llmServiceSuggestSections().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/v1/designs/{designId}/sections:suggest`.replace(`{${"designId"}}`, encodeURIComponent(String(requestParameters['designId']))),
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: LlmServiceSuggestSectionsRequestToJSON(requestParameters['body']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => V1SuggestSectionsResponseFromJSON(jsonValue));
    }

    /**
     * SuggestSections recommends relevant sections to add based on existing ones.
     */
    async llmServiceSuggestSections(requestParameters: LlmServiceSuggestSectionsOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<V1SuggestSectionsResponse> {
        const response = await this.llmServiceSuggestSectionsRaw(requestParameters, initOverrides);
        return await response.value();
    }

}
