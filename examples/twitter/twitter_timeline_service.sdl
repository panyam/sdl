// twitter_timeline_service.sdl

import HttpStatusCode, UserType from "./twitter_common.sdl"
import UserService from "./twitter_user_service.sdl"
import TweetService from "./twitter_tweet_service.sdl"
import StdCache from "std_native.sdl"

// twitter_timeline_service.sdl

import HttpStatusCode, UserType from "./twitter_common.sdl"
import UserService from "./twitter_user_service.sdl"
import TweetService from "./twitter_tweet_service.sdl"
import StdCache from "std_native.sdl" // Assuming this provides StdCache

component TimelineService {
  uses userService UserService
  uses tweetService TweetService
  uses timelineCache StdCache (DefaultTTL = 1min) // Example: Cache timelines for 1 minute

  // Configuration for timeline generation
  param TweetsPerUserToConsider Int = 10   // Max recent tweets to fetch from each followed user for ranking/consideration
  param MaxTimelineSize Int = 100          // Max tweets in the generated timeline (influences returned count)
  param DefaultFollowedUserType UserType = UserType.CASUAL // Assume followed users are 'CASUAL' for simplicity

  // Cost parameters for modeling latency
  param BaseTimelineServiceOverhead Duration = 1ms       // General overhead for a timeline request
  param CacheCheckOverhead Duration = 200us              // Cost of checking the timeline cache
  param FollowingListFetchOverhead Duration = 500us    // Cost to initiate fetching the list of followed users
  param TimelineAssemblyOverheadPerFollowedUser Duration = 20us // Overhead per followed user to initiate their tweet processing
  param PerCandidateTweetRankingCost Duration = 2us     // Cost to rank/consider one candidate tweet

  // Returns Outcomes[Tuple[Int, HttpStatusCode]]
  // Int: Number of tweets in the generated timeline.
  // HttpStatusCode: Status of timeline generation.
  method GetUserTimelineMetrics(viewerType UserType) Outcomes[Tuple[Int, HttpStatusCode]] {
    delay self.BaseTimelineServiceOverhead

    // 1. Check Cache
    // For this model, we'll simulate a cache check but mostly proceed to generation.
    // A real cache hit would return a pre-computed Tuple or a typical value.
    delay self.CacheCheckOverhead

    let cacheStatusCode = self.timelineCache.Get() // Returns HttpStatusCode as Int

    if cacheStatusCode == HttpStatusCode.OK {
      // Cache Hit: Return a typical successful outcome from cache.
      // The actual number of tweets would have been stored or is represented by a typical value.
      // For simplicity, let's assume a fixed typical size on cache hit.
      // This part could be more complex, e.g. cache stores Outcomes[Tuple[Int, HttpStatusCode]] as string
      // that needs to be "parsed" (conceptually) back.
      // For this example:
      log "Timeline cache hit for user type:", viewerType
      return dist { 1 => (self.MaxTimelineSize / 2, HttpStatusCode.OK) } // Return a typical outcome like half full timeline
    }
    log "Timeline cache miss for user type:", viewerType

    // 2. Cache Miss: Get how many users the 'viewerType' typically follows
    delay self.FollowingListFetchOverhead
    let numFollowing_dist = self.userService.GetFollowingCountMetrics(viewerType)
    let numFollowing_sample = sample numFollowing_dist

    if numFollowing_sample == 0 {
      log "User type", viewerType, "follows 0 users. Empty timeline."
      // Cache the empty result before returning
      // self.timelineCache.Put() // Conceptual pack
      return dist { 1 => (0, HttpStatusCode.OK) }
    }
    log "User type", viewerType, "follows", numFollowing_sample, "users. Proceeding to fetch candidates."

    // 3. Simulate fetching and processing candidate tweets
    let fetchAndRankOverallSuccess = true // Tracks if any sub-operation fails critically
    let accumulatedTimelineSize = 0      // Counts tweets that would make it to the timeline (before final capping)

    // Loop for each user being followed
    for numFollowing_sample {
      delay self.TimelineAssemblyOverheadPerFollowedUser // Cost to initiate processing for this followed user

      // A. Get how many recent tweets this *followed user* might have
      let followedUser_tweetCount_dist = self.tweetService.GetRecentTweetCountForUser(
                                              self.DefaultFollowedUserType, // Type of user being followed
                                              self.TweetsPerUserToConsider  // Max tweets to consider from them
                                          )
      let followedUser_tweetCount_sample = sample followedUser_tweetCount_dist

      // B. Accumulate delay for ranking/considering each candidate tweet from this followed user
      if followedUser_tweetCount_sample > 0 {
        for followedUser_tweetCount_sample { // Loop for each candidate tweet from this one followed user
          delay self.PerCandidateTweetRankingCost
        }
      }

      // C. Logic to determine how many of these 'followedUser_tweetCount_sample'
      //    are provisionally added to the timeline. This is about the *count*.
      //    The cost of *considering* them is handled by the inner loop's delay.
      //    Here, we simplify: assume all considered tweets from this user are candidates
      //    for the timeline, up to the point where the timeline is full.
      if fetchAndRankOverallSuccess { // Only add if no critical error has occurred yet
          if (accumulatedTimelineSize + followedUser_tweetCount_sample) <= self.MaxTimelineSize {
             // This arithmetic is for the *discrete count* of items, not for calculating a delay.
             set accumulatedTimelineSize accumulatedTimelineSize + followedUser_tweetCount_sample
          } else if accumulatedTimelineSize < self.MaxTimelineSize {
             // Fill up to MaxTimelineSize and stop conceptually adding more,
             // though the cost for considering remaining users/tweets still occurs.
             set accumulatedTimelineSize self.MaxTimelineSize
          }
      }

      // D. Simulate a small chance of error during this sub-operation
      if sample dist {999 => true, 1 => false} == false {
          log "Simulated error during candidate fetch/rank for one followed user."
          fetchAndRankOverallSuccess = false
          // Note: The loop continues to simulate the cost of attempting all,
          // but the final status will reflect the failure.
      }
    } // End loop for numFollowing_sample

    // 4. Determine final status and timeline size
    if not fetchAndRankOverallSuccess {
      log "Timeline generation failed due to errors in fetching/ranking candidates for user type:", viewerType
      // self.timelineCache.Put() // Cache failure outcome
      return dist { 1 => (0, HttpStatusCode.INTERNAL_SERVER_ERROR) } // Return 0 tweets on error
    }

    // Ensure final size doesn't exceed MaxTimelineSize (already handled mostly, but good for clarity)
    if accumulatedTimelineSize > self.MaxTimelineSize {
        accumulatedTimelineSize = self.MaxTimelineSize
    }

    log "Timeline generation successful for user type:", viewerType, ". Final size:", accumulatedTimelineSize
    // 5. Cache the successful result (conceptual)
    // self.timelineCache.Put()

    // For SimpleEval, we're returning a single outcome based on the sampled path.
    // An OutcomesEval would propagate the distributions through these steps.
    return dist { 1 => (accumulatedTimelineSize, HttpStatusCode.OK) }
  }
}
