// decl/lexer.go
package parser

import (
	"bufio"
	"bytes"
	"fmt"
	"io"
	"log"
	"strconv"
	"unicode"
)

// Ensure EOF is defined
const eof = 0

// Lexer structure
type Lexer struct {
	lookahead []rune
	reader    *bufio.Reader
	buf       bytes.Buffer // Temporary buffer for scanned text
	pos       int          // Current byte offset from the beginning of the input
	width     int          // Width of the last rune read, in bytes
	lastError error

	// Position tracking for the current token
	tokenStartPos  int    // Byte offset where the current token started
	tokenStartLine int    // Line number (1-based) where the current token started
	tokenStartCol  int    // Column number (rune-based, 1-based) where the current token started
	tokenText      string // Raw text of the current token

	// Current line and column (rune-based) in the input
	line int
	col  int

	parseResult *File // Field to store the final AST root, set by the parser
}

// NewLexer creates a new lexer instance
func NewLexer(r io.Reader) *Lexer {
	return &Lexer{
		reader: bufio.NewReader(r),
		pos:    0,
		line:   1,
		col:    1,
	}
}

// Error is called by the parser (or lexer itself) on an error.
func (l *Lexer) Error(s string) {
	l.lastError = fmt.Errorf("Error at Line %d, Col %d near '%s': %s", l.tokenStartLine, l.tokenStartCol, l.tokenText, s)
	fmt.Println(l.lastError) // For immediate feedback during development
}

// Pos returns the start byte offset of the most recently lexed token.
func (l *Lexer) Pos() int {
	return l.tokenStartPos
}

// End returns the end byte offset (current position) after lexing the most recent token.
func (l *Lexer) End() int {
	return l.pos
}

// Text returns the raw text of the most recently lexed token.
func (l *Lexer) Text() string {
	return l.tokenText
}

// --- Rune Reading Helpers (with line/col tracking) ---
func (l *Lexer) read() (r rune, width int) {
	r, width, err := l.reader.ReadRune()
	if err != nil {
		if err != io.EOF {
			// This error might be too low-level for the parser's Error function.
			// Consider how to propagate it. For now, store and return eof.
			l.lastError = fmt.Errorf("lexer read error: %v", err)
		}
		l.width = 0
		return eof, 0
	}
	l.width = width
	l.pos += width

	if r == '\n' {
		l.line++
		l.col = 1
	} else {
		l.col++
	}
	return r, width
}

func (l *Lexer) unread(r rune) {
	if l.width > 0 {
		l.pos -= l.width
		l.lookahead = append(l.lookahead, r)

		// Simplified column decrementing. Accurate rewind needs previous char type.
		if l.col > 1 {
			l.col--
		}
		// If unreading a newline, line count would be fixed on next read().
		l.width = 0
	}
}

func (l *Lexer) peek() rune {
	if len(l.lookahead) == 0 {
		r, _, err := l.reader.ReadRune()
		if err != nil {
			return eof
		}
		l.lookahead = []rune{r}
		return r
	}
	return l.lookahead[0]
}

// --- Scanning Functions ---
func (l *Lexer) skipWhitespace() bool {
	for {
		r, _ := l.read()
		if r == eof {
			return true
		}
		if unicode.IsSpace(r) {
			continue
		}
		if r == '/' {
			next, _ := l.read()
			if next == '/' { // Single-line comment
				for {
					r2, _ := l.read()
					if r2 == '\n' || r2 == eof {
						break
					}
				}
				continue
			} else if next == '*' { // Multi-line comment
				l.read()
				for {
					r1, _ := l.read()
					if r1 == eof {
						l.Error("unterminated multi-line comment")
						return true
					}
					if r1 == '*' {
						r2, _ := l.read()
						if r2 == '/' {
							break
						}
						if r2 == eof {
							l.Error("unterminated multi-line comment")
							return true
						}
						l.unread()
					}
				}
				continue
			} else {
				if next != eof {
					l.unread()
				}
				return false // Not a comment, unread the '/'
			}
		}
		l.unread()
		return false
	}
}

func (l *Lexer) scanIdentifierOrKeyword() (tok int, text string) {
	l.buf.Reset()
	for {
		r, _ := l.read()
		if r == eof {
			break
		}
		if !unicode.IsLetter(r) && !unicode.IsDigit(r) && r != '_' {
			l.unread()
			break
		}
		l.buf.WriteRune(r)
	}
	text = l.buf.String()
	switch text {
	case "component":
		return COMPONENT, text
	case "system":
		return SYSTEM, text
	case "param":
		return PARAM, text
	case "uses":
		return USES, text
	case "method":
		return METHOD, text
	case "instance":
		return INSTANCE, text
	case "analyze":
		return ANALYZE, text
	case "expect":
		return EXPECT, text
	case "let":
		return LET, text
	case "if":
		return IF, text
	case "else":
		return ELSE, text
	case "distribute":
		return DISTRIBUTE, text
	case "default":
		return DEFAULT, text
	case "return":
		return RETURN, text
	case "delay":
		return DELAY, text
	case "wait":
		return WAIT, text
	case "go":
		return GO, text
	case "log":
		return LOG, text
	case "switch":
		return SWITCH, text
	case "case":
		return CASE, text
	case "enum":
		return ENUM, text
	case "import":
		return IMPORT, text
	case "options":
		return OPTIONS, text
	case "true":
		return BOOL_LITERAL, text
	case "false":
		return BOOL_LITERAL, text
	case "for":
		return FOR, text
	case "int":
		return INT, text
	case "float":
		return FLOAT, text
	case "bool":
		return BOOL, text
	case "string":
		return STRING, text
	case "duration":
		return DURATION, text
	default:
		return IDENTIFIER, text
	}
}

func (l *Lexer) scanNumber() (tok int, text string) {
	l.buf.Reset()
	hasDecimal := false
	for {
		r, _ := l.read()
		if r == eof {
			break
		}
		if unicode.IsDigit(r) {
			l.buf.WriteRune(r)
		} else if r == '.' && !hasDecimal {
			if !unicode.IsDigit(l.peek()) {
				l.unread()
				break
			}
			hasDecimal = true
			l.buf.WriteRune(r)
		} else {
			l.unread()
			break
		}
	}
	text = l.buf.String()
	if hasDecimal {
		return FLOAT_LITERAL, text
	}
	return INT_LITERAL, text
}

func (l *Lexer) scanString() (tok int, content string) {
	l.buf.Reset()
	l.read() // Consume opening '"'
	for {
		r, _ := l.read()
		if r == eof {
			l.Error("unterminated string literal")
			return eof, ""
		}
		if r == '"' {
			break
		}
		if r == '\\' {
			esc, _ := l.read()
			if esc == eof {
				l.Error("unterminated string literal after escape")
				return eof, ""
			}
			switch esc {
			case 'n':
				l.buf.WriteRune('\n')
			case 't':
				l.buf.WriteRune('\t')
			case '\\':
				l.buf.WriteRune('\\')
			case '"':
				l.buf.WriteRune('"')
			default:
				l.Error(fmt.Sprintf("invalid escape sequence \\%c", esc))
				l.buf.WriteRune(esc)
			}
		} else {
			l.buf.WriteRune(r)
		}
	}
	return STRING_LITERAL, l.buf.String()
}

// Lex is the main lexing function called by the parser.
func (l *Lexer) Lex(lval *yySymType) int {
	if l.skipWhitespace() {
		return eof
	}

	l.tokenStartPos = l.pos
	l.tokenStartLine = l.line
	l.tokenStartCol = l.col
	l.tokenText = "" // Reset for current token

	r /*runeWidth*/, _ := l.read()
	if r == eof {
		return eof
	}

	startPosSnapshot := l.tokenStartPos // Save start for setting NodeInfo on simple tokens

	if unicode.IsLetter(r) || r == '_' {
		l.unread()
		tok, text := l.scanIdentifierOrKeyword()
		l.tokenText = text
		endPos := l.pos
		switch tok {
		case IDENTIFIER:
			lval.expr = newIdentifierExpr(text, startPosSnapshot, endPos)
		case BOOL_LITERAL:
			boolVal, _ := NewRuntimeValue(BoolType, text == "true")
			lval.expr = newLiteralExpr(boolVal, startPosSnapshot, endPos)
		case INT, FLOAT, BOOL, STRING, DURATION: // Type keywords
			lval.node = &TokenNode{NodeInfo: newNodeInfo(startPosSnapshot, endPos), Text: text}
		default: // Other keywords
			// Pass position via Node, if grammar expects Node for keywords
			lval.node = &TokenNode{NodeInfo: newNodeInfo(startPosSnapshot, endPos), Text: text}
			lval.sval = text // Keep sval too for compatibility if rules use it for ops
		}
		return tok
	}

	if unicode.IsDigit(r) || (r == '.' && unicode.IsDigit(l.peek())) {
		l.unread()
		numTok, numText := l.scanNumber()
		numEndPos := l.pos
		l.tokenText = numText
		unit := ""
		peekedRune := l.peek()
		if peekedRune == 'n' || peekedRune == 'u' || peekedRune == 'm' || peekedRune == 's' {
			firstUnitChar, _ := l.read()
			unit += string(firstUnitChar)
			if (firstUnitChar == 'n' || firstUnitChar == 'u' || firstUnitChar == 'm') && l.peek() == 's' {
				secondUnitChar, _ := l.read()
				unit += string(secondUnitChar)
			}
		}
		if _, ok := map[string]bool{"ns": true, "us": true, "ms": true, "s": true}[unit]; ok {
			l.tokenText += unit
			dur := parseDuration(numText, unit)
			durVal, _ := NewRuntimeValue(FloatType, dur)
			lval.expr = newLiteralExpr(durVal, startPosSnapshot, l.pos)
			return DURATION_LITERAL
		} else { // Not a valid duration unit, unread the unit chars if any
			for range len(unit) {
				l.unread()
			}
			// Not sure what to do here
			log.Println("numTok = ", numTok)
			log.Println("numText = ", numText)
			if numTok == INT_LITERAL {
				intVal, err := strconv.ParseInt(numText, 10, 64)
				if err != nil {
					l.Error(fmt.Sprintf("Invalid integer: %s", numText))
				}
				lval.expr = newLiteralExpr(IntValue(intVal), startPosSnapshot, numEndPos)
			} else if numTok == FLOAT_LITERAL {
				floatVal, err := strconv.ParseFloat(numText, 64)
				if err != nil {
					l.Error(fmt.Sprintf("Invalid float: %s", numText))
				}
				lval.expr = newLiteralExpr(FloatValue(floatVal), startPosSnapshot, numEndPos)
			} else {
				l.Error(fmt.Sprintf("Invalid numeric literal: %s", numText))
			}
			return numTok
		}
	}

	if r == '"' {
		l.unread()
		_, content := l.scanString()
		l.tokenText = `"` + content + `"`
		strVal, _ := NewRuntimeValue(StrType, content)
		lval.expr = newLiteralExpr(strVal, startPosSnapshot, l.pos)
		return STRING_LITERAL
	}

	// Operators and Punctuation - Default to single character token text
	l.tokenText = string(r)
	currentEndPos := l.pos // End pos for single char token

	// Handle multi-character operators
	switch r {
	case ':':
		if l.peek() == '=' {
			l.read()
			l.tokenText = ":="
			currentEndPos = l.pos
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return LET_ASSIGN
		}
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return int(':') // COLON
	case '=':
		if l.peek() == '=' {
			l.read()
			l.tokenText = "=="
			currentEndPos = l.pos
			lval.sval = "=="
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return EQ
		}
		if l.peek() == '>' {
			l.read()
			l.tokenText = "=>"
			currentEndPos = l.pos
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return ARROW
		}
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return ASSIGN
	case ';', '{', '}', '(', ')', ',', '.':
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return int(r)
	case '|':
		if l.peek() == '|' {
			l.read()
			l.tokenText = "||"
			currentEndPos = l.pos
			lval.sval = "||"
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return OR
		}
	case '&':
		if l.peek() == '&' {
			l.read()
			l.tokenText = "&&"
			currentEndPos = l.pos
			lval.sval = "&&"
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return AND
		}
	case '!':
		if l.peek() == '=' {
			l.read()
			l.tokenText = "!="
			currentEndPos = l.pos
			lval.sval = "!="
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return NEQ
		}
		lval.sval = "!"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return NOT
	case '<':
		if l.peek() == '=' {
			l.read()
			l.tokenText = "<="
			currentEndPos = l.pos
			lval.sval = "<="
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return LTE
		}
		lval.sval = "<"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return LT
	case '>':
		if l.peek() == '=' {
			l.read()
			l.tokenText = ">="
			currentEndPos = l.pos
			lval.sval = ">="
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return GTE
		}
		lval.sval = ">"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return GT
	case '+':
		if l.peek() == '=' {
			l.read()
			l.tokenText = "+="
			currentEndPos = l.pos
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return PLUS_ASSIGN
		}
		lval.sval = "+"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return PLUS
	case '-':
		if l.peek() == '=' {
			l.read()
			l.tokenText = "-="
			currentEndPos = l.pos
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return MINUS_ASSIGN
		}
		lval.sval = "-"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return MINUS
	case '*':
		if l.peek() == '=' {
			l.read()
			l.tokenText = "*="
			currentEndPos = l.pos
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return MUL_ASSIGN
		}
		lval.sval = "*"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return MUL
	case '/': // Comments handled in skipWhitespace
		if l.peek() == '=' {
			l.read()
			l.tokenText = "/="
			currentEndPos = l.pos
			lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
			return DIV_ASSIGN
		}
		lval.sval = "/"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return DIV
	case '%':
		lval.sval = "%"
		lval.node = &TokenNode{newNodeInfo(startPosSnapshot, currentEndPos), l.tokenText}
		return MOD
	}

	l.Error(fmt.Sprintf("unexpected character '%c'", r))
	return eof // Indicate an error that should halt parsing
}
